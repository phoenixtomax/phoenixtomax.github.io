<h1 id="backpropagation">Backpropagation</h1>

<h2 id="1-backpropagation-overview">1. Backpropagation Overview</h2>
<h4 id="forward-propagation">Forward Propagation</h4>
<p><img src="https://raw.githubusercontent.com/phoenixtomax/phoenixtomax.github.io/master/Res/BP2.jpg" alt="Forward Propagation" /></p>

<h4 id="forward-feature-matrix-multiplication">Forward Feature Matrix Multiplication</h4>
<p><img src="https://raw.githubusercontent.com/phoenixtomax/phoenixtomax.github.io/master/Res/BP1.jpg" alt="Forward Feature Matrix Multiplication" /></p>

<h4 id="single-neurons">Single Neurons</h4>
<p><img src="https://raw.githubusercontent.com/phoenixtomax/phoenixtomax.github.io/master/Res/BP3.jpg" alt="Single Neurons" /></p>

<h2 id="2-手撸反向传播">2. 手撸反向传播</h2>

<p>试着与Refs中一样手推反向传播的数学公式。</p>

<h4 id="my-propagation-1">My Propagation 1</h4>
<p><img src="https://raw.githubusercontent.com/phoenixtomax/phoenixtomax.github.io/master/Res/MY_BP1.jpg" alt="My Propagation 1" /></p>

<h4 id="my-propagation-2">My Propagation 2</h4>
<p><img src="https://raw.githubusercontent.com/phoenixtomax/phoenixtomax.github.io/master/Res/MY_BP2.jpg" alt="My Propagation 2" /></p>

<p>总而言之，就是梯度的计算到最后就是像一个将预测误差反向传播的过程。</p>

<blockquote>
  <p>Refs: https://blog.csdn.net/zhongkejingwang/article/details/44514073</p>
</blockquote>
